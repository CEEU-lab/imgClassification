{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EUROSAT Cnn optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Config\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if not gpus:\n",
    "    print(\"No GPU devices found. Ensure your system recognizes the GPU.\")\n",
    "else:\n",
    "    try:\n",
    "        # Limit TensorFlow to use only the first GPU\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(f\"Configured TensorFlow to use GPU: {gpus[0].name}\")\n",
    "\n",
    "        # Enable dynamic memory growth on the GPU\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"Memory growth enabled for the first GPU.\")\n",
    "\n",
    "        # Optional: Display additional GPU configuration details\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"Physical GPUs: {len(gpus)}, Logical GPUs: {len(logical_gpus)}\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"RuntimeError during GPU setup: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Further GPU diagnostics\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"CUDA device detected:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU availability:\", tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your condition\n",
    "download_condition = False  # Replace this with your actual condition\n",
    "\n",
    "if download_condition:\n",
    "    # Check if the 'data' directory exists, if not create it\n",
    "    if not os.path.exists('./data'):\n",
    "        os.makedirs('./data')\n",
    "\n",
    "    # Download the file and unzip it\n",
    "    !wget https://madm.dfki.de/files/sentinel/EuroSAT.zip -P /tmp/ --no-check-certificate\n",
    "    !unzip -qq /tmp/EuroSAT.zip -d ./data/\n",
    "\n",
    "else:\n",
    "    print(\"Download condition not met. Skipping download.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eurosat_model import count_images_in_subdirectories\n",
    "# Define the parent directory and subdirectories\n",
    "parent_directory = './data/2750/'  # Change this to your directory path\n",
    "subdirectories = ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', \n",
    "                  'Industrial', 'Pasture', 'PermanentCrop', 'Residential', \n",
    "                  'River', 'SeaLake']\n",
    "\n",
    "# Count the total number of images\n",
    "total_images = count_images_in_subdirectories(parent_directory, subdirectories)\n",
    "print(f\"Total number of images across all subdirectories: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the path to the EuroSAT dataset directory after unzipping\n",
    "data_dir = './data/2750/'\n",
    "\n",
    "# Define image size\n",
    "img_size = (64, 64)  # EuroSAT images are 64x64\n",
    "\n",
    "# Initialize empty lists for images and labels\n",
    "images = []\n",
    "labels = []\n",
    "class_names = []\n",
    "\n",
    "# Loop through each class directory and load images\n",
    "for i, class_name in enumerate(sorted(os.listdir(data_dir))):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(class_path):\n",
    "        class_names.append(class_name)\n",
    "        \n",
    "        # Loop through all image files in the class directory\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "            # Open and preprocess image\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize(img_size)  # Resize image\n",
    "            img = np.array(img) / 255.0  # Normalize pixel values\n",
    "            \n",
    "            # Append image and corresponding label\n",
    "            images.append(img)\n",
    "            labels.append(i)  # Label is the index of the class\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "print(f\"Loaded {len(X_train)} training images and {len(X_val)} validation images.\")\n",
    "print(f\"Class Names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0] #label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0]); #image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eurosat_model import plot_images\n",
    "\n",
    "# Plot a few images from the training dataset\n",
    "plot_images(X_train, y_train, class_names, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build a simple Cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions from the eurosat_model script\n",
    "from eurosat_model import (\n",
    "    create_data_generators, \n",
    "    build_cnn_model,\n",
    "    build_cnn_model_with_regularization, \n",
    "    train_model, \n",
    "    plot_training_history\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape and number of classes for EuroSAT\n",
    "input_shape = (64, 64, 3)\n",
    "num_classes = 10  # classes in EuroSAT\n",
    "\n",
    "# Build and summarize the CNN model\n",
    "model_A = build_cnn_model(input_shape, num_classes)\n",
    "model_A.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the path to the EuroSAT dataset directory after unzipping\n",
    "data_dir = './data/2750/'\n",
    "\n",
    "# Define image size and batch size for preprocessing\n",
    "img_size = (64, 64)  # EuroSAT images are 64x64\n",
    "batch_size = 32\n",
    "\n",
    "# Create an image data generator with data augmentation (not rescaling!)\n",
    "datagen_aug = ImageDataGenerator(\n",
    "    rotation_range=40,        # Rotate the image up to 40 degrees\n",
    "    width_shift_range=0.2,    # Shift the image horizontally by 20% of the width\n",
    "    height_shift_range=0.2,   # Shift the image vertically by 20% of the height\n",
    "    shear_range=0.2,          # Apply shear transformations\n",
    "    zoom_range=0.2,           # Zoom in/out by 20%\n",
    "    horizontal_flip=True,     # Flip images horizontally\n",
    "    fill_mode='nearest',      # Fill pixels after transformation\n",
    "    validation_split=0.2      # Reserve 20% of the data for validation\n",
    ")\n",
    "\n",
    "# Load the training set\n",
    "train_generator_aug = datagen_aug.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Use subset='training' to load the training set\n",
    ")\n",
    "\n",
    "# Load the validation set\n",
    "val_generator = datagen_aug.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Use subset='validation' to load the validation set\n",
    ")\n",
    "\n",
    "# Get the class names (directories inside the EuroSAT dataset folder)\n",
    "class_names = list(train_generator_aug.class_indices.keys())\n",
    "print(\"Class Names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eurosat_model import visualize_augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract one batch of images and labels for visualization\n",
    "X_train_sample, y_train_sample = next(train_generator_aug)\n",
    "\n",
    "# Use the function to visualize the original image and its augmentations for a specific index\n",
    "visualize_augmented_images(X_train_sample, y_train_sample, index=2, datagen_aug=datagen_aug, class_names=class_names, num_augments=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Train & evaluate cnn with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with data augmentation\n",
    "history = model_A.fit(\n",
    "    train_generator_aug,  # Training data with augmentation\n",
    "    validation_data=val_generator,  # Validation data\n",
    "    epochs=10,  # the number of epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history (accuracy and loss)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_A.save('eurosat_conv_model_A.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 & 4. Preventing Overfitting: Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Techniques to Prevent Overfitting**\n",
    "\n",
    "1. **Dropout:**\n",
    "\n",
    "Dropout is a regularization technique that randomly sets a fraction of input units to zero during each forward and backward pass in training. This forces the network to not rely too heavily on any particular neuron, making the model more robust.\n",
    "You can add Dropout layers after some of the dense or convolutional layers.\n",
    "\n",
    "2. **L1/L2 Regularization:**\n",
    "\n",
    "L1 (Lasso) and L2 (Ridge) regularization add a penalty to the loss function based on the size of the weights, discouraging the model from fitting the training data too closely.\n",
    "L2 is more common and can be added to layers by setting the kernel_regularizer parameter.\n",
    "\n",
    "3. **Batch Normalization:**\n",
    "\n",
    "Batch Normalization normalizes the input of each layer, stabilizing the learning process and often improving both training speed and model performance.\n",
    "It is usually added after convolutional or dense layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted Cnn setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory of your dataset\n",
    "data_dir = './data/2750/'\n",
    "\n",
    "# Create data generators\n",
    "train_generator, val_generator, class_names = create_data_generators(data_dir)\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (64, 64, 3)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Build the model\n",
    "model_B = build_cnn_model_with_regularization(input_shape, num_classes)\n",
    "\n",
    "# Train the model\n",
    "history = train_model(\n",
    "    model=model_B, n_epochs=10, n_patience=5, \n",
    "    train_generator=train_generator, val_generator=val_generator\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Regularization Can Cause Less Smooth Metric Curves\n",
    "\n",
    "#### Regularization Adds Noise to Training:\n",
    "- **Dropout**: Randomly drops units in the network during training, introducing noise and variability, which can cause training loss and accuracy to fluctuate from one batch to another.\n",
    "- **L1/L2 Regularization**: Penalizes large weights, forcing the model to learn simpler representations. This can slow down learning or cause the model to oscillate as it adjusts weights under these constraints.\n",
    "\n",
    "#### Regularization Prevents Overfitting, Not Noise:\n",
    "- Regularization techniques are designed to reduce overfitting by making the model less sensitive to noise in the training data. However, during the training process, these techniques can introduce their own form of noise, leading to fluctuating metrics.\n",
    "- The primary goal of regularization is to improve generalization, which might come at the cost of stability in training curves.\n",
    "\n",
    "#### Immediate Impact vs. Long-Term Stability:\n",
    "- Initially, regularization might make training and validation curves look more erratic because the model is learning under constraints.\n",
    "- Over time, if regularization is effective, you should observe that the validation metrics (especially loss) improve or stabilize, even if the training metrics fluctuate.\n",
    "\n",
    "#### Examples of Regularization Impact:\n",
    "- **Dropout**: Causes each mini-batch to behave differently because different neurons are dropped randomly, which can lead to jumps in accuracy and loss.\n",
    "- **L2 Regularization (Weight Decay)**: Shrinks weights towards zero, which can slow learning, causing small oscillations as the model gradually finds a balance between minimizing loss and keeping weights small.\n",
    "\n",
    "#### Strategies to Mitigate Fluctuations While Using Regularization:\n",
    "- **Gradual Learning Rate Decay**: Use learning rate schedules (like Exponential Decay) to gradually reduce the learning rate over time, helping to stabilize training as the model converges.\n",
    "- **Increase Batch Size**: Larger batch sizes reduce the variance in gradient updates, leading to smoother training curves even with regularization.\n",
    "- **Adjust Regularization Strength**: Fine-tune the dropout rate, L1/L2 penalties to find a balance where regularization helps without introducing excessive fluctuations.\n",
    "- **Use Smoothing for Visualization**: Apply exponential smoothing when plotting metrics to better visualize the overall trends despite inherent fluctuations.\n",
    "\n",
    "#### Key Takeaways:\n",
    "- Regularization introduces controlled instability during training but helps in achieving better generalization.\n",
    "- Fluctuations are normal and expected when regularization is applied; the goal is to see improved stability in validation metrics over the course of training.\n",
    "- Focus on long-term trends rather than short-term noise when evaluating the effect of regularization on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eurosat_model import visualize_weights\n",
    "\n",
    "# Visualizar los pesos de la 4 capa convolucional (Determinar si se observan patrones claros)\n",
    "visualize_weights(model_B, layer_index=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Configuración inicial\n",
    "data_dir = './data/2750/'  # Directorio de datos\n",
    "input_shape = (64, 64, 3)\n",
    "batch_size = 32\n",
    "num_folds = 3\n",
    "\n",
    "# Cargar nombres de archivos y etiquetas de clase\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for class_index, class_name in enumerate(os.listdir(data_dir)):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        all_images.append(os.path.join(class_dir, image_name))\n",
    "        all_labels.append(class_index)\n",
    "\n",
    "# Convertir listas a arrays de numpy\n",
    "all_images = np.array(all_images)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Variables para almacenar las métricas de cada pliegue\n",
    "accuracy_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# Configurar KFold para la validación cruzada\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Validación cruzada\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(all_images)):\n",
    "    print(f'Training fold {fold+1}/{num_folds}...')\n",
    "\n",
    "    # Dividir los datos en entrenamiento y validación para el pliegue actual\n",
    "    train_images, val_images = all_images[train_indices], all_images[val_indices]\n",
    "    train_labels, val_labels = all_labels[train_indices], all_labels[val_indices]\n",
    "\n",
    "    # Convertir las etiquetas a tipo string para que flow_from_dataframe funcione correctamente\n",
    "    train_df = pd.DataFrame({'filename': train_images, 'class': train_labels.astype(str)})\n",
    "    val_df = pd.DataFrame({'filename': val_images, 'class': val_labels.astype(str)})\n",
    "\n",
    "    # Crear generadores de datos\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=input_shape[:2],\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=input_shape[:2],\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Construir el modelo para el pliegue actual\n",
    "    model = build_cnn_model_with_regularization(input_shape, len(np.unique(all_labels)))\n",
    "\n",
    "    # Entrenar el modelo en el pliegue actual\n",
    "    history = train_model(\n",
    "        model=model, n_epochs=20, n_patience=5,\n",
    "        train_generator=train_generator, val_generator=val_generator\n",
    "    )\n",
    "\n",
    "    # Evaluar el modelo en los datos de validación del pliegue actual\n",
    "    scores = model.evaluate(val_generator, verbose=0)\n",
    "    print(f'Fold {fold+1} - Loss: {scores[0]} - Accuracy: {scores[1]}')\n",
    "\n",
    "    # Guardar las métricas del pliegue actual\n",
    "    accuracy_per_fold.append(scores[1])\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "# Calcular precisión y pérdida promedio de todos los pliegues\n",
    "average_accuracy = np.mean(accuracy_per_fold)\n",
    "average_loss = np.mean(loss_per_fold)\n",
    "print(f'Average Loss: {average_loss}')\n",
    "print(f'Average Accuracy: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "loss, accuracy = model_B.evaluate(val_generator)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history, smooth=True, smoothing_factor=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Fine tuning exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)#2.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "print(\"KerasTuner version:\", kt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eurosat_model import build_model_with_hp\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Defines if starting a fresh tuning session or resuming from a previous checkpoint\n",
    "start_fresh_tuning_session = True\n",
    "\n",
    "# Directory paths\n",
    "tuning_results_dir = 'tuner_results/eurosat_tuning'\n",
    "temp_val_dir = './temp_val_test_split'\n",
    "\n",
    "# Restart the tuning session if needed\n",
    "if start_fresh_tuning_session:\n",
    "    # Remove the existing tuner results directory\n",
    "    if os.path.exists(tuning_results_dir):\n",
    "        shutil.rmtree(tuning_results_dir, ignore_errors=True)\n",
    "        print(\"Restarted tuning session: Tuning results directory cleared.\")\n",
    "\n",
    "    # Remove the temporary validation and test split directory if it exists\n",
    "    if os.path.exists(temp_val_dir):\n",
    "        shutil.rmtree(temp_val_dir, ignore_errors=True)\n",
    "        print(\"Temporary validation/test split directory cleared.\")\n",
    "\n",
    "print(\"Session setup completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eurosat_model import create_extended_generators\n",
    "\n",
    "# Reset validation generator before tuning to avoid state issues\n",
    "#val_generator.reset()\n",
    "\n",
    "# Create the data generators\n",
    "train_generator, val_generator, test_generator = create_extended_generators(\n",
    "    data_dir=data_dir,\n",
    "    img_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    test_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "# Define steps per epoch\n",
    "steps_per_epoch = len(train_generator)\n",
    "validation_steps = val_generator.samples // val_generator.batch_size\n",
    "\n",
    "# Enhanced Early Stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',        # Monitor validation loss\n",
    "    patience=3,               # Allow more patience if gradual improvements occur\n",
    "    restore_best_weights=True, # Restore best weights based on validation loss\n",
    "    min_delta=0.001,           # Minimum change to be considered as an improvement\n",
    "    verbose=1                  # Verbose output to provide more insights during training\n",
    ")\n",
    "\n",
    "# Model Checkpoint to save the best model during training\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.keras',  # Path to save the best model\n",
    "    monitor='val_loss',        # Monitor the validation loss\n",
    "    save_best_only=True,       # Save only the best model during training\n",
    "    verbose=1                  # Show save messages\n",
    ")\n",
    "\n",
    "# Learning rate schedule callback (optional during tuning)\n",
    "def lr_scheduler(epoch, lr):\n",
    "    return lr * 0.9  # Reduce the learning rate gradually\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Use both callbacks during model training\n",
    "callbacks = [early_stopping, lr_callback, model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the hyperparameter search\n",
    "print(\"Starting hyperparameter search...\")\n",
    "\n",
    "# Initialize the tuner with the corrected parameters\n",
    "tuner = RandomSearch(\n",
    "    build_model_with_hp,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_results',\n",
    "    project_name='eurosat_tuning',\n",
    "    overwrite=True  # Ensures the session starts fresh\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=8,  # Define your desired number of epochs per trial\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks #[early_stopping]  # Ensures early stopping will prevent overfitting\n",
    ")\n",
    "\n",
    "# Retrieve the best model found by the tuner\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best Hyperparameters: \", best_hyperparameters.values)\n",
    "\n",
    "# Compile the best model with tuned optimizer settings if needed\n",
    "best_model.compile(\n",
    "    optimizer=best_model.optimizer,  # Use the optimizer configuration from tuning\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Retrain the best model on the combined training and validation data\n",
    "print(\"Retraining the best model on the combined training and validation data...\")\n",
    "best_model.fit(\n",
    "    train_generator,\n",
    "    epochs=8,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,#[early_stopping, lr_callback],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(test_generator)\n",
    "print(f\"Best Model Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Simplier model with train, val, test data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construcción del modelo CNN\n",
    "# Input shape and number of classes for EuroSAT\n",
    "input_shape = (64, 64, 3)\n",
    "num_classes = 10  # classes in EuroSAT\n",
    "\n",
    "# Build and summarize the CNN model\n",
    "model_C = build_cnn_model(input_shape, num_classes)\n",
    "\n",
    "model_C.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model_C.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model_C.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_C.save('model_C.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the best model\n",
    "model_C = load_model('model_C.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predictions = model_C.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to class indices\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Actual class labels\n",
    "actual_classes = test_generator.classes\n",
    "\n",
    "# Get the class labels from the generator\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Convert predicted indices to class labels\n",
    "predicted_labels = [class_labels[i] for i in predicted_classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with actual and predicted labels\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Label': [class_labels[i] for i in actual_classes],\n",
    "    'Predicted Label': predicted_labels\n",
    "})\n",
    "\n",
    "# Display a random sample of comparisons\n",
    "sample_comparisons = comparison_df.sample(10)\n",
    "print(sample_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get file paths from the test generator\n",
    "file_paths = test_generator.filepaths\n",
    "\n",
    "# Select a random subset for visualization\n",
    "num_samples = 5\n",
    "indices = np.random.choice(len(file_paths), num_samples, replace=False)\n",
    "\n",
    "# Plot sample images with actual and predicted labels\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, idx in enumerate(indices):\n",
    "    img = plt.imread(file_paths[idx])\n",
    "    plt.subplot(1, num_samples, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Actual: {comparison_df['Actual Label'][idx]}\\nPredicted: {comparison_df['Predicted Label'][idx]}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(actual_classes, predicted_classes)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPL",
   "language": "python",
   "name": "deepl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
