{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Config\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if not gpus:\n",
    "    print(\"No GPU devices found. Ensure your system recognizes the GPU.\")\n",
    "else:\n",
    "    try:\n",
    "        # Limit TensorFlow to use only the first GPU\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(f\"Configured TensorFlow to use GPU: {gpus[0].name}\")\n",
    "\n",
    "        # Enable dynamic memory growth on the GPU\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"Memory growth enabled for the first GPU.\")\n",
    "\n",
    "        # Optional: Display additional GPU configuration details\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"Physical GPUs: {len(gpus)}, Logical GPUs: {len(logical_gpus)}\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"RuntimeError during GPU setup: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# Further GPU diagnostics\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"CUDA device detected:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU availability:\", tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))\n",
    "\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eurosat_model import create_extended_generators, plot_training_history\n",
    "\n",
    "data_dir = './data/2750/'\n",
    "\n",
    "# Create the data generators\n",
    "train_generator, val_generator, test_generator = create_extended_generators(\n",
    "    data_dir=data_dir,\n",
    "    img_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    test_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "num_classes = 10\n",
    "\n",
    "# Configuración del modelo\n",
    "alexnet = Sequential()\n",
    "\n",
    "# Primera capa convolucional\n",
    "alexnet.add(Conv2D(96, kernel_size=(11, 11), strides=4, activation='relu', input_shape=input_shape))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "# Segunda capa convolucional\n",
    "alexnet.add(Conv2D(256, kernel_size=(5, 5), activation='relu', padding='same'))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "# Tercera, cuarta y quinta capas convolucionales\n",
    "alexnet.add(Conv2D(384, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "alexnet.add(Conv2D(384, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "alexnet.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "# Aplanamiento y capas densas\n",
    "alexnet.add(Flatten())\n",
    "alexnet.add(Dense(4096, activation='relu'))\n",
    "alexnet.add(Dropout(0.5))\n",
    "alexnet.add(Dense(4096, activation='relu'))\n",
    "alexnet.add(Dropout(0.5))\n",
    "\n",
    "# Capa de salida\n",
    "alexnet.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "# Compilación del modelo\n",
    "alexnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "alexnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only EarlyStopping when using LearningRateSchedule\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = alexnet.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]  # Only use callbacks that do not alter the learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Add, Activation, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "# Definición de un bloque residual\n",
    "def residual_block(x, filters, kernel_size=(3, 3), stride=1):\n",
    "    # Primera capa convolucional\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, kernel_size, strides=stride, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Segunda capa convolucional\n",
    "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Skip connection\n",
    "    if stride > 1:\n",
    "        shortcut = Conv2D(filters, (1, 1), strides=stride, padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Definición de la entrada\n",
    "input_tensor = Input(shape=(64, 64, 3))\n",
    "\n",
    "# Primeras capas convolucionales\n",
    "x = Conv2D(64, (7, 7), strides=2, padding='same', activation='relu')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "# Bloques residuales\n",
    "x = residual_block(x, filters=64)\n",
    "x = residual_block(x, filters=64)\n",
    "\n",
    "x = residual_block(x, filters=128, stride=2)\n",
    "x = residual_block(x, filters=128)\n",
    "\n",
    "x = residual_block(x, filters=256, stride=2)\n",
    "x = residual_block(x, filters=256)\n",
    "\n",
    "x = residual_block(x, filters=512, stride=2)\n",
    "x = residual_block(x, filters=512)\n",
    "\n",
    "# Capa de pooling global y capa de salida\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output_tensor = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Creación del modelo\n",
    "resnet = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "resnet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Use only EarlyStopping when using LearningRateSchedule\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "history = resnet.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]  # Only use callbacks that do not alter the learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Cargar el modelo VGG16 preentrenado en ImageNet, ajustando la entrada a 64x64 y sin incluir la capa de clasificación superior\n",
    "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Congelar las capas del modelo base para evitar que se actualicen durante el entrenamiento\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Añadir capas densas personalizadas para la clasificación\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(10, activation='softmax')(x)  # Ajustar para 10 clases\n",
    "\n",
    "# Crear el modelo final\n",
    "vgg = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compilar el modelo\n",
    "vgg.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "vgg.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Use only EarlyStopping when using LearningRateSchedule\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "history = vgg.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]  # Only use callbacks that do not alter the learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Predecir\n",
    "predictions = vgg.predict(test_generator)\n",
    "\n",
    "# Convert predictions to class indices\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Actual class labels\n",
    "actual_classes = test_generator.classes\n",
    "\n",
    "# Get the class labels from the generator\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Convert predicted indices to class labels\n",
    "predicted_labels = [class_labels[i] for i in predicted_classes]\n",
    "\n",
    "# Create a DataFrame with actual and predicted labels\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Label': [class_labels[i] for i in actual_classes],\n",
    "    'Predicted Label': predicted_labels\n",
    "})\n",
    "\n",
    "# Display a random sample of comparisons\n",
    "sample_comparisons = comparison_df.sample(10)\n",
    "print(sample_comparisons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get file paths from the test generator\n",
    "file_paths = test_generator.filepaths\n",
    "\n",
    "# Select a random subset for visualization\n",
    "num_samples = 5\n",
    "indices = np.random.choice(len(file_paths), num_samples, replace=False)\n",
    "\n",
    "# Plot sample images with actual and predicted labels\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, idx in enumerate(indices):\n",
    "    img = plt.imread(file_paths[idx])\n",
    "    plt.subplot(1, num_samples, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Actual: {comparison_df['Actual Label'][idx]}\\nPredicted: {comparison_df['Predicted Label'][idx]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(actual_classes, predicted_classes)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPL",
   "language": "python",
   "name": "deepl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
